{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683652e-09bd-49b5-bfc4-6e0bf8b2f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-28 13:06:40.689850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745838400.710663  501200 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745838400.719218  501200 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745838400.738773  501200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745838400.738792  501200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745838400.738794  501200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745838400.738796  501200 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 13:06:40.744049: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "import io\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Debug mode for CUDA errors\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# Load Yelp dataset\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Preprocessing\n",
    "train_df[\"Sentence\"] = train_df[\"text\"].str.lower()\n",
    "test_df[\"Sentence\"] = test_df[\"text\"].str.lower()\n",
    "train_df[\"Class\"] = train_df[\"label\"]\n",
    "test_df[\"Class\"] = test_df[\"label\"]\n",
    "train_df = train_df[[\"Sentence\", \"Class\"]]\n",
    "test_df = test_df[[\"Sentence\", \"Class\"]]\n",
    "\n",
    "#Downsample for faster dev\n",
    "train_df = train_df.sample(30000, random_state=42)\n",
    "test_df = test_df.sample(5000, random_state=42)\n",
    "\n",
    "# Split train/val\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df[\"Sentence\"].values,\n",
    "    train_df[\"Class\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "test_texts = test_df[\"Sentence\"].values\n",
    "test_labels = test_df[\"Class\"].values\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "\n",
    "class YelpDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Build datasets\n",
    "train_dataset = YelpDataset(train_encodings, train_labels)\n",
    "val_dataset = YelpDataset(val_encodings, val_labels)\n",
    "test_dataset = YelpDataset(test_encodings, test_labels)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=5\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter(\"runs/yelp_distilbert_experiment\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_preds, val_true = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = accuracy_score(val_true, val_preds)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # TensorBoard logging\n",
    "    writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Validation\", avg_val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Validation\", val_acc, epoch)\n",
    "\n",
    "# Final Testing\n",
    "model.eval()\n",
    "test_preds, test_true = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "print(\"\\n--- Final Test Results ---\")\n",
    "print(\"Accuracy:\", accuracy_score(test_true, test_preds))\n",
    "print(\"Precision:\", precision_score(test_true, test_preds, average='macro'))\n",
    "print(\"Recall:\", recall_score(test_true, test_preds, average='macro'))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_true, test_preds, target_names=[f\"{i+1} Star\" for i in range(5)]))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_true, test_preds)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[f\"{i+1} Star\" for i in range(5)], yticklabels=[f\"{i+1} Star\" for i in range(5)])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_distilbert.png\")\n",
    "plt.show()\n",
    "\n",
    "# TensorBoard Confusion Matrix Logging\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "buf = io.BytesIO()\n",
    "plt.savefig(buf, format='jpeg')\n",
    "buf.seek(0)\n",
    "image = torchvision.transforms.ToTensor()(plt.imread(buf))\n",
    "writer.add_image(\"Confusion Matrix\", image, 0)\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd46370-20d4-4ed2-8019-13dac7502893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
